{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas , numpy\n",
    "features = pandas.read_csv('./features.csv', index_col='match_id')\n",
    "test_features = pandas.read_csv('./features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'first_blood_time'\n",
      "'first_blood_team'\n",
      "'first_blood_player1'\n",
      "'first_blood_player2'\n",
      "'radiant_bottle_time'\n",
      "'radiant_courier_time'\n",
      "'radiant_flying_courier_time'\n",
      "'radiant_first_ward_time'\n",
      "'dire_bottle_time'\n",
      "'dire_courier_time'\n",
      "'dire_flying_courier_time'\n",
      "'dire_first_ward_time'\n"
     ]
    }
   ],
   "source": [
    "#empty cells count:\n",
    "for column in features:\n",
    "    dif = len( features.index ) - features[ column ].count()\n",
    "    if dif > 0:\n",
    "        print \"'\" + column + \"'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'first_blood_time' empty cells :  19553\n",
    "'first_blood_team' empty cells :  19553\n",
    "'first_blood_player1' empty cells :  19553\n",
    "'first_blood_player2' empty cells :  43987\n",
    "'radiant_bottle_time' empty cells :  15691\n",
    "'radiant_courier_time' empty cells :  692\n",
    "'radiant_flying_courier_time' empty cells :  27479\n",
    "'radiant_first_ward_time' empty cells :  1836\n",
    "'dire_bottle_time' empty cells :  16143\n",
    "'dire_courier_time' empty cells :  676\n",
    "'dire_flying_courier_time' empty cells :  26098\n",
    "'dire_first_ward_time' empty cells :  1826\n",
    "\n",
    "*_first_ward_time пропуски потому что не было вардов в игре. Тоже самое с first_blood, в игре не было убийств. Если с количеством предметов в игре можно обойтись \"0\" в случае, если таковых приобретено в течении игры не было, то в случае с характеристиками предметов, коих приобретено не было, все несколько сложнее, поэтому и пропуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.replace( '' , numpy.nan , inplace=True )\n",
    "features.fillna( 0,inplace=True)\n",
    "test_features.replace( '' , numpy.nan , inplace=True )\n",
    "test_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "целевая переменная : \"radiant_win\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#разделим данные на матрицу характеристик и вектор классов\n",
    "ignore_labels = [\"radiant_win\" , \"match_id\"]\n",
    "X = features.select( lambda x: x in test_features.columns.values and not x in ignore_labels , axis=1 ).as_matrix()\n",
    "Y = features.select( lambda x: x == \"radiant_win\" , axis=1 ).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm.libsvm import predict_proba\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import random\n",
    "from sklearn.metrics import log_loss , roc_auc_score\n",
    "def testAbst(cv,N,X,Y):\n",
    "    #pick random samples from indices vector to speed up calculation\n",
    "    indices = random.sample(range(0,len(X)), N)\n",
    "    x = X[ indices ]\n",
    "    y = Y[ indices ]\n",
    "    from sklearn.model_selection import KFold , cross_val_score\n",
    "    kf = KFold( n_splits = 5 , shuffle = True , random_state=241 )\n",
    "    sum = 0.0\n",
    "    for train_indices, test_indices in kf.split(x):\n",
    "        cv.fit( x[train_indices] , y[train_indices] )\n",
    "        pred = cv.predict_proba(x[test_indices])[:, 1]\n",
    "        sum+= roc_auc_score( y[test_indices] , pred )\n",
    "    #return avg area under roc\n",
    "    return sum/5\n",
    "#5000 is enough\n",
    "def testBoosting(range,N,X,Y):\n",
    "    print \"Boosting\"\n",
    "    for num in range:\n",
    "        print num, \":\" , testAbst(GradientBoostingClassifier(n_estimators=num, random_state=241),N,X,Y)\n",
    "def testLogReg(range,N,X,Y):\n",
    "    print \"logReg\"\n",
    "    for regk in range:\n",
    "        print regk , \":\" , testAbst(LogisticRegression(penalty =\"l2\",C=regk),N,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting\n",
      "30 : 0.689744877956\n",
      "Time elapsed: 0:01:10.076000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "testBoosting([ 30 ],X.shape[0],X,Y)\n",
    "\n",
    "print 'Time elapsed:', datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting\n",
      "10 : 0.658525714926\n",
      "20 : 0.666494971528\n",
      "30 : 0.671254649462\n",
      "100 : 0.7042305657\n"
     ]
    }
   ],
   "source": [
    "testBoosting([ 10 , 20 , 30 , 100 ],5000,X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "результат улучшается, но время обучения тоже. Для ускорения можно использовать подмножество выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logReg\n",
      "0.001 : 0.513446681145\n",
      "Time elapsed: 0:00:01.679000\n",
      "logReg\n",
      "0.001 : 0.519001063905\n",
      "0.01 : 0.505890125162\n",
      "0.1 : 0.51830330524\n",
      "10.0 : 0.519764958233\n",
      "100.0 : 0.517493812543\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "testLogReg([ 1.0e-3 ],X.shape[0],X,Y)\n",
    "\n",
    "print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "testLogReg([ 1.0e-3 , 1.0e-2 , 1.0e-1 , 1.0e1 , 1.0e2 ],5000,X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качество логистической регрессии ниже, в виду наличия шума в признаках. время обучения ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logReg\n",
      "0.001 : 0.711083866188\n",
      "0.01 : 0.712162982448\n",
      "0.1 : 0.705755304459\n",
      "10.0 : 0.697817089818\n",
      "100.0 : 0.70474231211\n",
      "Boosting\n",
      "10 : 0.651068097338\n",
      "20 : 0.668242749842\n",
      "30 : 0.674395240321\n",
      "100 : 0.682008725538\n"
     ]
    }
   ],
   "source": [
    "ignore_labels = [\"radiant_win\" , \"match_id\",\"lobby_type\",\"start_time\",\"r1_hero\",\"r2_hero\",\"r3_hero\",\"r4_hero\",\"r5_hero\",\"d1_hero\",\"d2_hero\",\"d3_hero\",\"d4_hero\",\"d5_hero\"]\n",
    "X = features.select( lambda x: x in test_features.columns.values and not x in ignore_labels , axis=1 ).as_matrix()\n",
    "Y = features.select( lambda x: x == \"radiant_win\" , axis=1 ).as_matrix().ravel()\n",
    "testLogReg([ 1.0e-3 , 1.0e-2 , 1.0e-1 , 1.0e1 , 1.0e2 ],5000,X,Y)\n",
    "testBoosting([ 10 , 20 , 30 , 100 ],5000,X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, качество классификатора основанного на решающих деревьях не изменилось, в то время как качество линейного классификатора значительно повысилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max hero id: 112\n",
      "unique heroes count in sample : 108\n"
     ]
    }
   ],
   "source": [
    "category_labels = [\"r1_hero\",\"r2_hero\",\"r3_hero\",\"r4_hero\",\"r5_hero\",\"d1_hero\",\"d2_hero\",\"d3_hero\",\"d4_hero\",\"d5_hero\"]\n",
    "cathegory_dataframe = features.select( lambda x: x in test_features.columns.values and x in category_labels , axis=1 )\n",
    "unique_heroes = set()\n",
    "max_hero_id = 0\n",
    "for column in cathegory_dataframe:\n",
    "    values = cathegory_dataframe[column].value_counts()\n",
    "    unique_heroes |= set(values.index)\n",
    "unique_heroes = list(unique_heroes)\n",
    "unique_heroes.sort()\n",
    "max_hero_id = unique_heroes[ len(unique_heroes) - 1 ]\n",
    "print \"max hero id:\" , max_hero_id\n",
    "print \"unique heroes count in sample :\", len(unique_heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pick_matrix = numpy.zeros(shape=(len(cathegory_dataframe.index),max_hero_id))\n",
    "for i, match_id in enumerate(cathegory_dataframe.index):\n",
    "    for p in xrange(5):\n",
    "        pick_matrix[i, cathegory_dataframe.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        pick_matrix[i, cathegory_dataframe.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_full = numpy.concatenate([X,pick_matrix],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logReg\n",
      "0.001 : 0.718879007733\n",
      "0.01 : 0.730229437803\n",
      "0.1 : 0.721349027288\n",
      "10.0 : 0.742075073804\n",
      "100.0 : 0.726907938081\n"
     ]
    }
   ],
   "source": [
    "testLogReg([ 1.0e-3 , 1.0e-2 , 1.0e-1 , 1.0e1 , 1.0e2 ],5000,X_full,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качество классификатора после учета героев повысилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum and minimum probabilities: 0.998852190469 0.00114780953128\n"
     ]
    }
   ],
   "source": [
    "samples = random.sample(range(0,len(X)), 5000)\n",
    "logcv = LogisticRegression(penalty =\"l2\",C=0.01)\n",
    "logcv.fit( X_full[samples] , Y[samples] )\n",
    "Y_predict = logcv.predict_proba( X_full )\n",
    "print \"maximum and minimum probabilities:\" , Y_predict.max() , Y_predict.min()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
