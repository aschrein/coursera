{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas, sklearn\n",
    "class_data = pandas.read_csv( \"classification.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range( 0 , class_data.shape[ 0 ] ):\n",
    "    if class_data[ \"true\" ][ i ] == 1 and class_data[ \"pred\" ][ i ] == 1:\n",
    "        tp += 1\n",
    "    if class_data[ \"true\" ][ i ] == 0 and class_data[ \"pred\" ][ i ] == 0:\n",
    "        tn += 1\n",
    "    if class_data[ \"true\" ][ i ] == 1 and class_data[ \"pred\" ][ i ] == 0:\n",
    "        fn += 1\n",
    "    if class_data[ \"true\" ][ i ] == 0 and class_data[ \"pred\" ][ i ] == 1:\n",
    "        fp += 1\n",
    "print tp , fp , fn , tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.accuracy_score( class_data[ \"true\" ] , class_data[ \"pred\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.558441558442\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.precision_score( class_data[ \"true\" ] , class_data[ \"pred\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.421568627451\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.recall_score( class_data[ \"true\" ] , class_data[ \"pred\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480446927374\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.f1_score( class_data[ \"true\" ] , class_data[ \"pred\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48044692737447786"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.558441558442 * 0.421568627451*2.0/(0.558441558442 + 0.421568627451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     true  score_logreg  score_svm  score_knn  score_tree\n",
      "0       0      0.683832   0.145976   0.787063    0.500000\n",
      "1       1      0.801966   0.239511   1.000000    0.833333\n",
      "2       0      0.382315  -0.245701   0.000000    0.000000\n",
      "3       1      0.506797  -0.137058   0.000000    0.105263\n",
      "4       1      0.488781  -0.154148   0.000000    0.105263\n",
      "5       0      0.108506  -0.790864   0.000000    0.000000\n",
      "6       0      0.413749  -0.185143   0.283053    0.363636\n",
      "7       0      0.961081   0.830973   1.000000    1.000000\n",
      "8       0      0.055733  -0.872805   0.000000    0.100000\n",
      "9       0      0.168708  -0.518390   0.000000    0.100000\n",
      "10      1      0.504716  -0.103459   0.698631    0.833333\n",
      "11      1      0.700781   0.104391   1.000000    0.833333\n",
      "12      0      0.310665  -0.301488   0.676880    0.363636\n",
      "13      0      0.784460   0.195189   1.000000    0.923077\n",
      "14      0      0.160733  -0.611195   0.655103    0.315789\n",
      "15      1      0.799574   0.331874   1.000000    1.000000\n",
      "16      0      0.582998  -0.089084   0.435303    0.923077\n",
      "17      1      0.814842   0.283855   0.551823    0.833333\n",
      "18      0      0.157332  -0.631128   0.572756    0.315789\n",
      "19      1      0.931500   0.708483   1.000000    1.000000\n",
      "20      0      0.138797  -0.686697   0.000000    0.315789\n",
      "21      1      0.274198  -0.431631   0.797432    0.642857\n",
      "22      0      0.720033   0.230868   0.701967    0.700000\n",
      "23      1      0.843546   0.355761   1.000000    1.000000\n",
      "24      0      0.609126   0.084097   1.000000    0.700000\n",
      "25      1      0.880773   0.423232   1.000000    1.000000\n",
      "26      0      0.239080  -0.373287   0.625865    0.363636\n",
      "27      0      0.305787  -0.342313   0.000000    0.000000\n",
      "28      1      0.543229  -0.093911   0.000000    0.105263\n",
      "29      1      0.074923  -0.875135   0.356250    0.000000\n",
      "..    ...           ...        ...        ...         ...\n",
      "170     1      0.963559   0.919219   1.000000    1.000000\n",
      "171     0      0.358193  -0.277359   0.000000    0.000000\n",
      "172     1      0.728585   0.162791   1.000000    0.833333\n",
      "173     0      0.956966   0.791260   1.000000    1.000000\n",
      "174     1      0.921236   0.587108   0.636871    0.700000\n",
      "175     1      0.488522  -0.179402   0.723928    0.400000\n",
      "176     1      0.634594  -0.000936   0.329428    0.400000\n",
      "177     0      0.212360  -0.445750   0.000000    0.100000\n",
      "178     0      0.546161  -0.079479   0.280409    0.105263\n",
      "179     1      0.816888   0.275750   0.629734    0.833333\n",
      "180     1      0.936342   0.700641   1.000000    1.000000\n",
      "181     1      0.345238  -0.254075   0.815816    0.363636\n",
      "182     1      0.775077   0.226086   1.000000    0.833333\n",
      "183     0      0.784289   0.240379   1.000000    0.833333\n",
      "184     0      0.391728  -0.328802   0.000000    0.400000\n",
      "185     1      0.446609  -0.163247   0.000000    0.363636\n",
      "186     1      0.369691  -0.263503   0.298588    0.000000\n",
      "187     0      0.373856  -0.307583   0.000000    0.105263\n",
      "188     1      0.101603  -0.707600   0.000000    0.100000\n",
      "189     0      0.592363  -0.051362   0.000000    0.400000\n",
      "190     0      0.282557  -0.393812   0.000000    0.000000\n",
      "191     1      0.850252   0.358618   1.000000    1.000000\n",
      "192     0      0.563431  -0.072862   0.000000    0.400000\n",
      "193     0      0.255245  -0.447265   0.650820    0.315789\n",
      "194     1      0.903727   0.531599   0.000000    0.700000\n",
      "195     0      0.573801  -0.088203   0.284192    0.400000\n",
      "196     0      0.624422  -0.012315   0.205437    0.400000\n",
      "197     1      0.425538  -0.135673   0.382351    0.700000\n",
      "198     0      0.905270   0.583806   1.000000    1.000000\n",
      "199     0      0.275594  -0.422160   0.743567    0.642857\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "mclass_data = pandas.read_csv( \"scores.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71918767507\n",
      "0.63025210084\n",
      "______\n",
      "0.708683473389\n",
      "0.622807017544\n",
      "______\n",
      "0.635154061625\n",
      "0.606557377049\n",
      "______\n",
      "0.691926770708\n",
      "0.651785714286\n",
      "______\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.roc_auc_score( mclass_data[ \"true\"] , mclass_data[ \"score_logreg\"] )\n",
    "d = sklearn.metrics.precision_recall_curve( mclass_data[ \"true\"] , mclass_data[ \"score_logreg\"] )\n",
    "maxp = 0.0\n",
    "for i in range( 0 , d[ 0 ].size ):\n",
    "    if d[ 1 ][ i ] > 0.7 and d[ 0 ][ i ] > maxp:\n",
    "        maxp = d[ 0 ][ i ]\n",
    "print maxp\n",
    "print \"______\"\n",
    "print sklearn.metrics.roc_auc_score( mclass_data[ \"true\"] , mclass_data[ \"score_svm\"] )\n",
    "d = sklearn.metrics.precision_recall_curve( mclass_data[ \"true\"] , mclass_data[ \"score_svm\"] )\n",
    "maxp = 0.0\n",
    "for i in range( 0 , d[ 0 ].size ):\n",
    "    if d[ 1 ][ i ] > 0.7 and d[ 0 ][ i ] > maxp:\n",
    "        maxp = d[ 0 ][ i ]\n",
    "print maxp\n",
    "print \"______\"\n",
    "print sklearn.metrics.roc_auc_score( mclass_data[ \"true\"] , mclass_data[ \"score_knn\"] )\n",
    "d = sklearn.metrics.precision_recall_curve( mclass_data[ \"true\"] , mclass_data[ \"score_knn\"] )\n",
    "maxp = 0.0\n",
    "for i in range( 0 , d[ 0 ].size ):\n",
    "    if d[ 1 ][ i ] > 0.7 and d[ 0 ][ i ] > maxp:\n",
    "        maxp = d[ 0 ][ i ]\n",
    "print maxp\n",
    "print \"______\"\n",
    "print sklearn.metrics.roc_auc_score( mclass_data[ \"true\"] , mclass_data[ \"score_tree\"] )\n",
    "d = sklearn.metrics.precision_recall_curve( mclass_data[ \"true\"] , mclass_data[ \"score_tree\"] )\n",
    "maxp = 0.0\n",
    "for i in range( 0 , d[ 0 ].size ):\n",
    "    if d[ 1 ][ i ] > 0.7 and d[ 0 ][ i ] > maxp:\n",
    "        maxp = d[ 0 ][ i ]\n",
    "print maxp\n",
    "print \"______\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
